{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv('../data/processed/train_data_processed.csv')\n",
    "test = pd.read_csv('../data/processed/test_data_processed.csv')\n",
    "val = pd.read_csv('../data/processed/val_data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more feature engineering\n",
    "# use encoder to encode OCCURRED_ON_DATE column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['OCCURRED_ON_DATE'] = le.fit_transform(train['OCCURRED_ON_DATE'])\n",
    "test['OCCURRED_ON_DATE'] = le.transform(test['OCCURRED_ON_DATE'])\n",
    "val['OCCURRED_ON_DATE'] = le.transform(val['OCCURRED_ON_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/datetime_encoder.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save le \n",
    "import joblib\n",
    "joblib.dump(le, '../models/datetime_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop _id column\n",
    "\n",
    "test = test.drop('_id', axis=1)\n",
    "val = val.drop('_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable\n",
    "y_train = train['Severe_crimes']\n",
    "y_test = test['Severe_crimes']\n",
    "y_val = val['Severe_crimes']\n",
    "\n",
    "# define the features\n",
    "X_train = train.drop(['Severe_crimes'], axis=1)\n",
    "X_test = test.drop(['Severe_crimes'], axis=1)\n",
    "X_val = val.drop(['Severe_crimes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wangd\\.conda\\envs\\BCAIML\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\wangd\\.conda\\envs\\BCAIML\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\wangd\\.conda\\envs\\BCAIML\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\wangd\\.conda\\envs\\BCAIML\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\wangd\\.conda\\envs\\BCAIML\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "964/964 [==============================] - 3s 2ms/step - loss: 7.3420 - accuracy: 0.8907 - val_loss: 0.1911 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.4153 - accuracy: 0.9285 - val_loss: 0.2043 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2689 - accuracy: 0.9308 - val_loss: 0.1859 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2309 - accuracy: 0.9316 - val_loss: 0.1817 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.2206 - accuracy: 0.9319 - val_loss: 0.1768 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2080 - accuracy: 0.9336 - val_loss: 0.1753 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1961 - accuracy: 0.9357 - val_loss: 0.1480 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.9387 - val_loss: 0.1255 - val_accuracy: 0.9365\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1585 - accuracy: 0.9402 - val_loss: 0.1056 - val_accuracy: 0.9507\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1417 - accuracy: 0.9438 - val_loss: 0.1009 - val_accuracy: 0.9522\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1329 - accuracy: 0.9462 - val_loss: 0.1008 - val_accuracy: 0.9526\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1250 - accuracy: 0.9485 - val_loss: 0.0979 - val_accuracy: 0.9615\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9519 - val_loss: 0.0918 - val_accuracy: 0.9655\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9559 - val_loss: 0.0925 - val_accuracy: 0.9622\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9610 - val_loss: 0.0930 - val_accuracy: 0.9611\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1046 - accuracy: 0.9637 - val_loss: 0.0863 - val_accuracy: 0.9722\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1047 - accuracy: 0.9653 - val_loss: 0.1016 - val_accuracy: 0.9712\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9656 - val_loss: 0.0829 - val_accuracy: 0.9746\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9682 - val_loss: 0.0793 - val_accuracy: 0.9758\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.9687 - val_loss: 0.0794 - val_accuracy: 0.9769\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0924 - accuracy: 0.9713 - val_loss: 0.0750 - val_accuracy: 0.9791\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0913 - accuracy: 0.9711 - val_loss: 0.0735 - val_accuracy: 0.9781\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.9728 - val_loss: 0.0696 - val_accuracy: 0.9796\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.9734 - val_loss: 0.0704 - val_accuracy: 0.9775\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0883 - accuracy: 0.9726 - val_loss: 0.0644 - val_accuracy: 0.9818\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0871 - accuracy: 0.9729 - val_loss: 0.0680 - val_accuracy: 0.9827\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0869 - accuracy: 0.9727 - val_loss: 0.0706 - val_accuracy: 0.9785\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0882 - accuracy: 0.9708 - val_loss: 0.0672 - val_accuracy: 0.9808\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.9730 - val_loss: 0.0701 - val_accuracy: 0.9785\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0863 - accuracy: 0.9719 - val_loss: 0.0667 - val_accuracy: 0.9845\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0862 - accuracy: 0.9721 - val_loss: 0.0688 - val_accuracy: 0.9792\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0859 - accuracy: 0.9729 - val_loss: 0.0735 - val_accuracy: 0.9780\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.9719 - val_loss: 0.0668 - val_accuracy: 0.9803\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9729 - val_loss: 0.0709 - val_accuracy: 0.9774\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9724 - val_loss: 0.0684 - val_accuracy: 0.9785\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9721 - val_loss: 0.0612 - val_accuracy: 0.9847\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0833 - accuracy: 0.9722 - val_loss: 0.0696 - val_accuracy: 0.9794\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9743 - val_loss: 0.0661 - val_accuracy: 0.9788\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0842 - accuracy: 0.9722 - val_loss: 0.0655 - val_accuracy: 0.9784\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0837 - accuracy: 0.9733 - val_loss: 0.0745 - val_accuracy: 0.9769\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9726 - val_loss: 0.0721 - val_accuracy: 0.9776\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0813 - accuracy: 0.9754 - val_loss: 0.0616 - val_accuracy: 0.9847\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.0629 - val_accuracy: 0.9887\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0826 - accuracy: 0.9736 - val_loss: 0.0647 - val_accuracy: 0.9787\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0824 - accuracy: 0.9745 - val_loss: 0.0710 - val_accuracy: 0.9820\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0866 - accuracy: 0.9722 - val_loss: 0.0676 - val_accuracy: 0.9803\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0801 - accuracy: 0.9747 - val_loss: 0.0586 - val_accuracy: 0.9836\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.9755 - val_loss: 0.0570 - val_accuracy: 0.9822\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.9747 - val_loss: 0.0694 - val_accuracy: 0.9819\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.9728 - val_loss: 0.0604 - val_accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "# build a CNN model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=7, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 0s 768us/step\n",
      "Accuracy: 0.9804137039431157\n",
      "Confusion Matrix: [[14297   190]\n",
      " [  113   870]]\n",
      "F1 Score: 0.8516886930983847\n"
     ]
    }
   ],
   "source": [
    "# use the model on validation data and evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# evaluate the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:', confusion)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               4096      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178689 (698.00 KB)\n",
      "Trainable params: 178689 (698.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 5s 4ms/step - loss: 1.9188 - accuracy: 0.8950 - val_loss: 0.4700 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.2627 - accuracy: 0.9248 - val_loss: 0.2639 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1983 - accuracy: 0.9303 - val_loss: 0.1985 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1694 - accuracy: 0.9316 - val_loss: 0.1387 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1524 - accuracy: 0.9316 - val_loss: 0.1390 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1441 - accuracy: 0.9318 - val_loss: 0.1468 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1361 - accuracy: 0.9532 - val_loss: 0.1064 - val_accuracy: 0.9741\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1310 - accuracy: 0.9614 - val_loss: 0.1189 - val_accuracy: 0.9717\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1303 - accuracy: 0.9641 - val_loss: 0.1212 - val_accuracy: 0.9751\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1228 - accuracy: 0.9658 - val_loss: 0.0937 - val_accuracy: 0.9741\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1200 - accuracy: 0.9682 - val_loss: 0.1660 - val_accuracy: 0.9677\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1216 - accuracy: 0.9682 - val_loss: 0.0875 - val_accuracy: 0.9749\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1194 - accuracy: 0.9688 - val_loss: 0.0925 - val_accuracy: 0.9747\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1136 - accuracy: 0.9705 - val_loss: 0.1430 - val_accuracy: 0.9646\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1137 - accuracy: 0.9708 - val_loss: 0.1352 - val_accuracy: 0.9560\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1117 - accuracy: 0.9704 - val_loss: 0.0961 - val_accuracy: 0.9690\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1125 - accuracy: 0.9706 - val_loss: 0.0984 - val_accuracy: 0.9696\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.0939 - val_accuracy: 0.9732\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1101 - accuracy: 0.9709 - val_loss: 0.1437 - val_accuracy: 0.9702\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1115 - accuracy: 0.9706 - val_loss: 0.0929 - val_accuracy: 0.9685\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1097 - accuracy: 0.9712 - val_loss: 0.1954 - val_accuracy: 0.9531\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1105 - accuracy: 0.9707 - val_loss: 0.1240 - val_accuracy: 0.9725\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1092 - accuracy: 0.9703 - val_loss: 0.1223 - val_accuracy: 0.9659\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1063 - accuracy: 0.9722 - val_loss: 0.1017 - val_accuracy: 0.9714\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1064 - accuracy: 0.9717 - val_loss: 0.2372 - val_accuracy: 0.9644\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1080 - accuracy: 0.9711 - val_loss: 0.1997 - val_accuracy: 0.9628\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1064 - accuracy: 0.9730 - val_loss: 0.1293 - val_accuracy: 0.9701\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1055 - accuracy: 0.9725 - val_loss: 0.2187 - val_accuracy: 0.9704\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1079 - accuracy: 0.9728 - val_loss: 0.1896 - val_accuracy: 0.9646\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1095 - accuracy: 0.9715 - val_loss: 0.1236 - val_accuracy: 0.9655\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.9722 - val_loss: 0.0956 - val_accuracy: 0.9667\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.9711 - val_loss: 0.1136 - val_accuracy: 0.9703\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1056 - accuracy: 0.9721 - val_loss: 0.1294 - val_accuracy: 0.9607\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1042 - accuracy: 0.9716 - val_loss: 0.0888 - val_accuracy: 0.9676\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1061 - accuracy: 0.9713 - val_loss: 0.0851 - val_accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1048 - accuracy: 0.9708 - val_loss: 0.1579 - val_accuracy: 0.9379\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1037 - accuracy: 0.9710 - val_loss: 0.1158 - val_accuracy: 0.9657\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1035 - accuracy: 0.9720 - val_loss: 0.1255 - val_accuracy: 0.9703\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1027 - accuracy: 0.9721 - val_loss: 0.2129 - val_accuracy: 0.9664\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1004 - accuracy: 0.9722 - val_loss: 0.1353 - val_accuracy: 0.9654\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1036 - accuracy: 0.9719 - val_loss: 0.1435 - val_accuracy: 0.9666\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1026 - accuracy: 0.9724 - val_loss: 0.0868 - val_accuracy: 0.9674\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1007 - accuracy: 0.9722 - val_loss: 0.2084 - val_accuracy: 0.9253\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 3s 4ms/step - loss: 0.1049 - accuracy: 0.9712 - val_loss: 0.1997 - val_accuracy: 0.9510\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1049 - accuracy: 0.9723 - val_loss: 0.1782 - val_accuracy: 0.9643\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1000 - accuracy: 0.9716 - val_loss: 0.1358 - val_accuracy: 0.9691\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1025 - accuracy: 0.9716 - val_loss: 0.0979 - val_accuracy: 0.9668\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1030 - accuracy: 0.9714 - val_loss: 0.0848 - val_accuracy: 0.9673\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1031 - accuracy: 0.9724 - val_loss: 0.1239 - val_accuracy: 0.9567\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 4s 4ms/step - loss: 0.1072 - accuracy: 0.9715 - val_loss: 0.1146 - val_accuracy: 0.9654\n"
     ]
    }
   ],
   "source": [
    "# build a deeper CNN model\n",
    "model_deeper = Sequential()\n",
    "model_deeper.add(Dense(512, input_dim=7, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(256, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(128, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(64, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(32, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model_deeper.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_deeper.summary()\n",
    "\n",
    "# fit the model\n",
    "history_deeper = model_deeper.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 1ms/step\n",
      "Accuracy: 0.9654169360051713\n",
      "Confusion Matrix: [[14023   464]\n",
      " [   71   912]]\n",
      "F1 Score: 0.7732089868588384\n"
     ]
    }
   ],
   "source": [
    "# use the model on validation data and evaluate\n",
    "y_pred = model_deeper.predict(X_val)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# evaluate the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:', confusion)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 4.6706 - accuracy: 0.9069 - val_loss: 0.1600 - val_accuracy: 0.9491\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.2398 - accuracy: 0.9280 - val_loss: 0.1171 - val_accuracy: 0.9456\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1644 - accuracy: 0.9376 - val_loss: 0.1064 - val_accuracy: 0.9540\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1337 - accuracy: 0.9473 - val_loss: 0.0994 - val_accuracy: 0.9613\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1193 - accuracy: 0.9551 - val_loss: 0.0991 - val_accuracy: 0.9729\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1115 - accuracy: 0.9629 - val_loss: 0.1022 - val_accuracy: 0.9739\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.0886 - val_accuracy: 0.9750\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9683 - val_loss: 0.0886 - val_accuracy: 0.9732\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9709 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0945 - accuracy: 0.9725 - val_loss: 0.0867 - val_accuracy: 0.9751\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9729 - val_loss: 0.0816 - val_accuracy: 0.9795\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9740 - val_loss: 0.0784 - val_accuracy: 0.9763\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0880 - accuracy: 0.9736 - val_loss: 0.0813 - val_accuracy: 0.9754\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.9746 - val_loss: 0.0811 - val_accuracy: 0.9772\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0867 - accuracy: 0.9747 - val_loss: 0.0791 - val_accuracy: 0.9808\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.0774 - val_accuracy: 0.9775\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.0782 - val_accuracy: 0.9764\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9762 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0831 - accuracy: 0.9768 - val_loss: 0.0898 - val_accuracy: 0.9738\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0799 - accuracy: 0.9773 - val_loss: 0.0689 - val_accuracy: 0.9798\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9771 - val_loss: 0.0743 - val_accuracy: 0.9803\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.9781 - val_loss: 0.0728 - val_accuracy: 0.9803\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0756 - accuracy: 0.9782 - val_loss: 0.0626 - val_accuracy: 0.9856\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.9786 - val_loss: 0.0634 - val_accuracy: 0.9780\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0747 - accuracy: 0.9783 - val_loss: 0.0644 - val_accuracy: 0.9856\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9788 - val_loss: 0.0671 - val_accuracy: 0.9827\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.9793 - val_loss: 0.0625 - val_accuracy: 0.9810\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0700 - accuracy: 0.9803 - val_loss: 0.0647 - val_accuracy: 0.9869\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9812 - val_loss: 0.0600 - val_accuracy: 0.9813\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9809 - val_loss: 0.0538 - val_accuracy: 0.9873\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0637 - val_accuracy: 0.9822\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9822 - val_loss: 0.0574 - val_accuracy: 0.9836\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9818 - val_loss: 0.0538 - val_accuracy: 0.9871\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9809 - val_loss: 0.0689 - val_accuracy: 0.9879\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0667 - accuracy: 0.9811 - val_loss: 0.0592 - val_accuracy: 0.9813\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.0572 - val_accuracy: 0.9875\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0660 - accuracy: 0.9816 - val_loss: 0.0565 - val_accuracy: 0.9855\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0623 - accuracy: 0.9838 - val_loss: 0.0537 - val_accuracy: 0.9904\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0623 - accuracy: 0.9837 - val_loss: 0.0578 - val_accuracy: 0.9880\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0604 - accuracy: 0.9847 - val_loss: 0.0528 - val_accuracy: 0.9883\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0606 - accuracy: 0.9852 - val_loss: 0.0474 - val_accuracy: 0.9915\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0610 - accuracy: 0.9853 - val_loss: 0.0453 - val_accuracy: 0.9927\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0572 - accuracy: 0.9863 - val_loss: 0.0447 - val_accuracy: 0.9910\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0661 - accuracy: 0.9812 - val_loss: 0.0534 - val_accuracy: 0.9895\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0628 - accuracy: 0.9832 - val_loss: 0.0510 - val_accuracy: 0.9911\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0602 - accuracy: 0.9841 - val_loss: 0.0522 - val_accuracy: 0.9868\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0586 - accuracy: 0.9847 - val_loss: 0.0458 - val_accuracy: 0.9893\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0564 - accuracy: 0.9858 - val_loss: 0.0420 - val_accuracy: 0.9932\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0562 - accuracy: 0.9859 - val_loss: 0.0454 - val_accuracy: 0.9931\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0543 - accuracy: 0.9863 - val_loss: 0.0442 - val_accuracy: 0.9917\n",
      "484/484 [==============================] - 1s 930us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 3s 2ms/step - loss: 4.2816 - accuracy: 0.8965 - val_loss: 0.1766 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.2264 - accuracy: 0.9313 - val_loss: 0.1316 - val_accuracy: 0.9399\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1672 - accuracy: 0.9347 - val_loss: 0.1111 - val_accuracy: 0.9423\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1438 - accuracy: 0.9368 - val_loss: 0.0998 - val_accuracy: 0.9430\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1310 - accuracy: 0.9410 - val_loss: 0.0960 - val_accuracy: 0.9599\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1208 - accuracy: 0.9504 - val_loss: 0.0942 - val_accuracy: 0.9653\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1133 - accuracy: 0.9567 - val_loss: 0.0933 - val_accuracy: 0.9718\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1083 - accuracy: 0.9587 - val_loss: 0.0912 - val_accuracy: 0.9721\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1066 - accuracy: 0.9586 - val_loss: 0.0881 - val_accuracy: 0.9690\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9598 - val_loss: 0.0856 - val_accuracy: 0.9704\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9585 - val_loss: 0.0845 - val_accuracy: 0.9715\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9622 - val_loss: 0.0812 - val_accuracy: 0.9729\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9630 - val_loss: 0.0797 - val_accuracy: 0.9727\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0997 - accuracy: 0.9621 - val_loss: 0.0805 - val_accuracy: 0.9713\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0981 - accuracy: 0.9629 - val_loss: 0.0824 - val_accuracy: 0.9736\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9651 - val_loss: 0.0814 - val_accuracy: 0.9753\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9659 - val_loss: 0.0778 - val_accuracy: 0.9750\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9678 - val_loss: 0.0737 - val_accuracy: 0.9754\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9695 - val_loss: 0.0754 - val_accuracy: 0.9755\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.9709 - val_loss: 0.0786 - val_accuracy: 0.9758\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.9727 - val_loss: 0.0718 - val_accuracy: 0.9787\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9736 - val_loss: 0.0797 - val_accuracy: 0.9752\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0844 - accuracy: 0.9734 - val_loss: 0.0690 - val_accuracy: 0.9763\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.9707 - val_loss: 0.0823 - val_accuracy: 0.9766\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0833 - accuracy: 0.9732 - val_loss: 0.0759 - val_accuracy: 0.9782\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9740 - val_loss: 0.0706 - val_accuracy: 0.9765\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0825 - accuracy: 0.9734 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0898 - val_accuracy: 0.9577\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0784 - accuracy: 0.9751 - val_loss: 0.0672 - val_accuracy: 0.9790\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.0632 - val_accuracy: 0.9796\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0752 - accuracy: 0.9767 - val_loss: 0.0618 - val_accuracy: 0.9816\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0742 - accuracy: 0.9775 - val_loss: 0.0541 - val_accuracy: 0.9880\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0737 - accuracy: 0.9774 - val_loss: 0.0588 - val_accuracy: 0.9810\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0713 - accuracy: 0.9786 - val_loss: 0.0561 - val_accuracy: 0.9870\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0756 - accuracy: 0.9745 - val_loss: 0.0502 - val_accuracy: 0.9916\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9802 - val_loss: 0.0586 - val_accuracy: 0.9795\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0717 - accuracy: 0.9801 - val_loss: 0.0586 - val_accuracy: 0.9836\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0726 - accuracy: 0.9799 - val_loss: 0.1010 - val_accuracy: 0.9452\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9786 - val_loss: 0.0529 - val_accuracy: 0.9904\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.0562 - val_accuracy: 0.9926\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0677 - accuracy: 0.9810 - val_loss: 0.0484 - val_accuracy: 0.9919\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9818 - val_loss: 0.0523 - val_accuracy: 0.9930\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9815 - val_loss: 0.0519 - val_accuracy: 0.9854\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0645 - accuracy: 0.9828 - val_loss: 0.0497 - val_accuracy: 0.9913\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 0.0535 - val_accuracy: 0.9864\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.0493 - val_accuracy: 0.9913\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0655 - accuracy: 0.9818 - val_loss: 0.0606 - val_accuracy: 0.9794\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0681 - accuracy: 0.9814 - val_loss: 0.0535 - val_accuracy: 0.9921\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.0453 - val_accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9826 - val_loss: 0.0605 - val_accuracy: 0.9798\n",
      "484/484 [==============================] - 0s 819us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 1.5521 - accuracy: 0.9166 - val_loss: 0.1926 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.9320 - val_loss: 0.1702 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1916 - accuracy: 0.9321 - val_loss: 0.1291 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1557 - accuracy: 0.9362 - val_loss: 0.1103 - val_accuracy: 0.9458\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1347 - accuracy: 0.9442 - val_loss: 0.1001 - val_accuracy: 0.9548\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.9500 - val_loss: 0.1030 - val_accuracy: 0.9630\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9594 - val_loss: 0.0921 - val_accuracy: 0.9699\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9650 - val_loss: 0.0920 - val_accuracy: 0.9721\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9675 - val_loss: 0.0886 - val_accuracy: 0.9712\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9714\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9699 - val_loss: 0.0846 - val_accuracy: 0.9712\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9710 - val_loss: 0.0840 - val_accuracy: 0.9718\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0943 - accuracy: 0.9711 - val_loss: 0.0823 - val_accuracy: 0.9744\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9716 - val_loss: 0.0796 - val_accuracy: 0.9768\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9730 - val_loss: 0.0835 - val_accuracy: 0.9772\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9736 - val_loss: 0.0804 - val_accuracy: 0.9742\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9744 - val_loss: 0.0793 - val_accuracy: 0.9750\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9743 - val_loss: 0.0756 - val_accuracy: 0.9778\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9756 - val_loss: 0.0749 - val_accuracy: 0.9790\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9754 - val_loss: 0.0759 - val_accuracy: 0.9763\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0823 - accuracy: 0.9755 - val_loss: 0.0754 - val_accuracy: 0.9776\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9759 - val_loss: 0.0708 - val_accuracy: 0.9780\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.9765 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9771 - val_loss: 0.0691 - val_accuracy: 0.9786\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.9773 - val_loss: 0.0659 - val_accuracy: 0.9802\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.9779 - val_loss: 0.0643 - val_accuracy: 0.9809\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.9783 - val_loss: 0.0723 - val_accuracy: 0.9745\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 0.0672 - val_accuracy: 0.9794\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9782 - val_loss: 0.0692 - val_accuracy: 0.9787\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9791 - val_loss: 0.0600 - val_accuracy: 0.9815\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0753 - accuracy: 0.9792 - val_loss: 0.0624 - val_accuracy: 0.9829\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0732 - accuracy: 0.9793 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0630 - val_accuracy: 0.9794\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0749 - accuracy: 0.9788 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9784 - val_loss: 0.0584 - val_accuracy: 0.9820\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.9785 - val_loss: 0.0626 - val_accuracy: 0.9794\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.9793 - val_loss: 0.0629 - val_accuracy: 0.9820\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0700 - accuracy: 0.9806 - val_loss: 0.0600 - val_accuracy: 0.9817\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9793 - val_loss: 0.0626 - val_accuracy: 0.9798\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.9794 - val_loss: 0.0620 - val_accuracy: 0.9800\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9794 - val_loss: 0.0555 - val_accuracy: 0.9849\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.9798 - val_loss: 0.0596 - val_accuracy: 0.9842\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0699 - accuracy: 0.9807 - val_loss: 0.0575 - val_accuracy: 0.9844\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0684 - accuracy: 0.9803 - val_loss: 0.0567 - val_accuracy: 0.9868\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 0.0516 - val_accuracy: 0.9837\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0689 - accuracy: 0.9800 - val_loss: 0.0520 - val_accuracy: 0.9830\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0690 - accuracy: 0.9802 - val_loss: 0.0491 - val_accuracy: 0.9908\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9803 - val_loss: 0.0529 - val_accuracy: 0.9824\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0682 - accuracy: 0.9799 - val_loss: 0.0479 - val_accuracy: 0.9920\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9798 - val_loss: 0.0593 - val_accuracy: 0.9915\n",
      "484/484 [==============================] - 0s 829us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 6.2183 - accuracy: 0.8955 - val_loss: 0.2342 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.3221 - accuracy: 0.9296 - val_loss: 0.1792 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.2360 - accuracy: 0.9317 - val_loss: 0.1846 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.2283 - accuracy: 0.9318 - val_loss: 0.1717 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.2056 - accuracy: 0.9321 - val_loss: 0.1533 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1795 - accuracy: 0.9322 - val_loss: 0.1251 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1621 - accuracy: 0.9324 - val_loss: 0.1139 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9323 - val_loss: 0.1018 - val_accuracy: 0.9365\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1276 - accuracy: 0.9471 - val_loss: 0.1006 - val_accuracy: 0.9690\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.9602 - val_loss: 0.1017 - val_accuracy: 0.9688\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1197 - accuracy: 0.9628 - val_loss: 0.0964 - val_accuracy: 0.9735\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.9641 - val_loss: 0.0955 - val_accuracy: 0.9736\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1152 - accuracy: 0.9650 - val_loss: 0.0945 - val_accuracy: 0.9732\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1107 - accuracy: 0.9663 - val_loss: 0.0940 - val_accuracy: 0.9736\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9682 - val_loss: 0.0901 - val_accuracy: 0.9738\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9730\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.9683 - val_loss: 0.0935 - val_accuracy: 0.9696\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9689 - val_loss: 0.0929 - val_accuracy: 0.9741\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9698 - val_loss: 0.0860 - val_accuracy: 0.9758\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0974 - accuracy: 0.9702 - val_loss: 0.0836 - val_accuracy: 0.9744\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9703 - val_loss: 0.0837 - val_accuracy: 0.9721\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9693 - val_loss: 0.0840 - val_accuracy: 0.9749\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9705 - val_loss: 0.0833 - val_accuracy: 0.9719\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0955 - accuracy: 0.9703 - val_loss: 0.0790 - val_accuracy: 0.9752\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9703 - val_loss: 0.0794 - val_accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0916 - accuracy: 0.9708 - val_loss: 0.0738 - val_accuracy: 0.9747\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0913 - accuracy: 0.9719 - val_loss: 0.0809 - val_accuracy: 0.9739\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0889 - accuracy: 0.9736 - val_loss: 0.0777 - val_accuracy: 0.9761\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.9737 - val_loss: 0.0699 - val_accuracy: 0.9844\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9745 - val_loss: 0.0707 - val_accuracy: 0.9761\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9752 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0813 - accuracy: 0.9758 - val_loss: 0.0701 - val_accuracy: 0.9816\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.9762 - val_loss: 0.0728 - val_accuracy: 0.9794\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9750 - val_loss: 0.0677 - val_accuracy: 0.9776\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0782 - accuracy: 0.9762 - val_loss: 0.0628 - val_accuracy: 0.9788\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0624 - val_accuracy: 0.9842\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.0617 - val_accuracy: 0.9825\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9781 - val_loss: 0.0655 - val_accuracy: 0.9795\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0744 - accuracy: 0.9781 - val_loss: 0.0616 - val_accuracy: 0.9899\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0730 - accuracy: 0.9782 - val_loss: 0.0560 - val_accuracy: 0.9856\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9786 - val_loss: 0.0697 - val_accuracy: 0.9790\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0762 - accuracy: 0.9765 - val_loss: 0.0715 - val_accuracy: 0.9796\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0741 - accuracy: 0.9777 - val_loss: 0.0595 - val_accuracy: 0.9793\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.0709 - val_accuracy: 0.9790\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0755 - accuracy: 0.9769 - val_loss: 0.0577 - val_accuracy: 0.9860\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.9779 - val_loss: 0.0714 - val_accuracy: 0.9790\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.9779 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0699 - accuracy: 0.9795 - val_loss: 0.0652 - val_accuracy: 0.9794\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0716 - accuracy: 0.9788 - val_loss: 0.0689 - val_accuracy: 0.9792\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0698 - accuracy: 0.9796 - val_loss: 0.0513 - val_accuracy: 0.9917\n",
      "484/484 [==============================] - 0s 766us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 8.9372 - accuracy: 0.8954 - val_loss: 0.4041 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.9281 - val_loss: 0.1946 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.9313 - val_loss: 0.1852 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2292 - accuracy: 0.9319 - val_loss: 0.1856 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.2215 - accuracy: 0.9322 - val_loss: 0.1752 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.2025 - accuracy: 0.9322 - val_loss: 0.1565 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1841 - accuracy: 0.9335 - val_loss: 0.1319 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1635 - accuracy: 0.9393 - val_loss: 0.1141 - val_accuracy: 0.9392\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1490 - accuracy: 0.9433 - val_loss: 0.1052 - val_accuracy: 0.9515\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1446 - accuracy: 0.9465 - val_loss: 0.1019 - val_accuracy: 0.9566\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1360 - accuracy: 0.9488 - val_loss: 0.0979 - val_accuracy: 0.9599\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1271 - accuracy: 0.9534 - val_loss: 0.0976 - val_accuracy: 0.9613\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1240 - accuracy: 0.9547 - val_loss: 0.0927 - val_accuracy: 0.9687\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9600 - val_loss: 0.0905 - val_accuracy: 0.9722\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.9604 - val_loss: 0.0858 - val_accuracy: 0.9711\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9632 - val_loss: 0.0872 - val_accuracy: 0.9717\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1067 - accuracy: 0.9635 - val_loss: 0.0847 - val_accuracy: 0.9677\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1000 - accuracy: 0.9654 - val_loss: 0.0835 - val_accuracy: 0.9773\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0980 - accuracy: 0.9677 - val_loss: 0.0767 - val_accuracy: 0.9806\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0961 - accuracy: 0.9694 - val_loss: 0.0775 - val_accuracy: 0.9763\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.9703 - val_loss: 0.0764 - val_accuracy: 0.9775\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0917 - accuracy: 0.9703 - val_loss: 0.0709 - val_accuracy: 0.9782\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.9713 - val_loss: 0.0698 - val_accuracy: 0.9797\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.9713 - val_loss: 0.0710 - val_accuracy: 0.9800\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.9731 - val_loss: 0.0670 - val_accuracy: 0.9794\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.9721 - val_loss: 0.0646 - val_accuracy: 0.9803\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.9734 - val_loss: 0.0646 - val_accuracy: 0.9813\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.9721 - val_loss: 0.0716 - val_accuracy: 0.9781\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.9721 - val_loss: 0.0735 - val_accuracy: 0.9774\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.9727 - val_loss: 0.0680 - val_accuracy: 0.9869\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.9727 - val_loss: 0.0651 - val_accuracy: 0.9784\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.0654 - val_accuracy: 0.9808\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.0708 - val_accuracy: 0.9771\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.9738 - val_loss: 0.0614 - val_accuracy: 0.9803\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.9755 - val_loss: 0.0553 - val_accuracy: 0.9860\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.0675 - val_accuracy: 0.9781\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.9731 - val_loss: 0.0606 - val_accuracy: 0.9795\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.9734 - val_loss: 0.0654 - val_accuracy: 0.9782\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.9756 - val_loss: 0.0619 - val_accuracy: 0.9793\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.9749 - val_loss: 0.0591 - val_accuracy: 0.9887\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.9755 - val_loss: 0.0672 - val_accuracy: 0.9785\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.9744 - val_loss: 0.0606 - val_accuracy: 0.9824\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.9749 - val_loss: 0.0616 - val_accuracy: 0.9820\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0762 - accuracy: 0.9763 - val_loss: 0.0581 - val_accuracy: 0.9833\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.9753 - val_loss: 0.0597 - val_accuracy: 0.9836\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.9754 - val_loss: 0.0665 - val_accuracy: 0.9785\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.9751 - val_loss: 0.0598 - val_accuracy: 0.9813\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.9748 - val_loss: 0.0588 - val_accuracy: 0.9862\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.9746 - val_loss: 0.0567 - val_accuracy: 0.9847\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.9750 - val_loss: 0.0636 - val_accuracy: 0.9793\n",
      "484/484 [==============================] - 1s 1ms/step\n",
      "[0.9317821258593338, 0.8497359577532405, 0.9286880783886772, 0.9314040728831725, 0.8448108632395733]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test different dropout rates\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "f1_scores = []\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=7, activation='relu'))\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "    # use the model on validation data and evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    # f1 score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f1_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the dropout rates vs f1 scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dropout_rates, f1_scores)\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Dropout Rate vs F1 Score')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 1024)              8192      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 707585 (2.70 MB)\n",
      "Trainable params: 707585 (2.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# final model, use a 0.15 dropout rate\n",
    "model_final = Sequential()\n",
    "model_final.add(Dense(1024, input_dim=7, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(512, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(128, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(64, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(32, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_final.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "964/964 [==============================] - 8s 7ms/step - loss: 0.3484 - accuracy: 0.9327 - val_loss: 0.0961 - val_accuracy: 0.9605\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.1085 - accuracy: 0.9619 - val_loss: 0.1580 - val_accuracy: 0.9597\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.1029 - accuracy: 0.9675 - val_loss: 0.0991 - val_accuracy: 0.9679\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0961 - accuracy: 0.9705 - val_loss: 0.0802 - val_accuracy: 0.9756\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0926 - accuracy: 0.9724 - val_loss: 0.0854 - val_accuracy: 0.9747\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0881 - accuracy: 0.9733 - val_loss: 0.0917 - val_accuracy: 0.9745\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0844 - accuracy: 0.9749 - val_loss: 0.0735 - val_accuracy: 0.9773\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0816 - accuracy: 0.9759 - val_loss: 0.0795 - val_accuracy: 0.9756\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0795 - accuracy: 0.9772 - val_loss: 0.0704 - val_accuracy: 0.9831\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0734 - accuracy: 0.9792 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0730 - accuracy: 0.9789 - val_loss: 0.0607 - val_accuracy: 0.9797\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 6s 7ms/step - loss: 0.0735 - accuracy: 0.9790 - val_loss: 0.0724 - val_accuracy: 0.9778\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 6s 7ms/step - loss: 0.0711 - accuracy: 0.9793 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.0496 - val_accuracy: 0.9886\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.0790 - val_accuracy: 0.9789\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0612 - accuracy: 0.9829 - val_loss: 0.0582 - val_accuracy: 0.9819\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0625 - accuracy: 0.9826 - val_loss: 0.0634 - val_accuracy: 0.9790\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0694 - accuracy: 0.9797 - val_loss: 0.0583 - val_accuracy: 0.9800\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.0719 - val_accuracy: 0.9756\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0739 - accuracy: 0.9795 - val_loss: 0.0833 - val_accuracy: 0.9754\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0685 - accuracy: 0.9819 - val_loss: 0.0495 - val_accuracy: 0.9866\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 6s 7ms/step - loss: 0.0659 - accuracy: 0.9829 - val_loss: 0.0858 - val_accuracy: 0.9758\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0816 - accuracy: 0.9746 - val_loss: 0.0713 - val_accuracy: 0.9757\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0798 - accuracy: 0.9743 - val_loss: 0.0707 - val_accuracy: 0.9789\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0730 - accuracy: 0.9794 - val_loss: 0.0509 - val_accuracy: 0.9891\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0695 - accuracy: 0.9808 - val_loss: 0.0746 - val_accuracy: 0.9767\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0685 - accuracy: 0.9815 - val_loss: 0.0716 - val_accuracy: 0.9769\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0660 - accuracy: 0.9823 - val_loss: 0.0435 - val_accuracy: 0.9913\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0706 - accuracy: 0.9804 - val_loss: 0.0542 - val_accuracy: 0.9884\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0624 - accuracy: 0.9829 - val_loss: 0.0592 - val_accuracy: 0.9794\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0702 - accuracy: 0.9790 - val_loss: 0.0726 - val_accuracy: 0.9787\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0609 - accuracy: 0.9812 - val_loss: 0.0745 - val_accuracy: 0.9789\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.0700 - val_accuracy: 0.9754\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0698 - accuracy: 0.9777 - val_loss: 0.0404 - val_accuracy: 0.9926\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0603 - accuracy: 0.9828 - val_loss: 0.0468 - val_accuracy: 0.9844\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0697 - accuracy: 0.9789 - val_loss: 0.0471 - val_accuracy: 0.9916\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0729 - accuracy: 0.9782 - val_loss: 0.0405 - val_accuracy: 0.9928\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0919 - accuracy: 0.9697 - val_loss: 0.0655 - val_accuracy: 0.9795\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0766 - accuracy: 0.9739 - val_loss: 0.0567 - val_accuracy: 0.9792\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0652 - accuracy: 0.9819 - val_loss: 0.0423 - val_accuracy: 0.9923\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0658 - accuracy: 0.9816 - val_loss: 0.0719 - val_accuracy: 0.9775\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0629 - accuracy: 0.9825 - val_loss: 0.0733 - val_accuracy: 0.9798\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0791 - accuracy: 0.9746 - val_loss: 0.0689 - val_accuracy: 0.9847\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 7s 8ms/step - loss: 0.0578 - accuracy: 0.9845 - val_loss: 0.0550 - val_accuracy: 0.9862\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 8s 9ms/step - loss: 0.0737 - accuracy: 0.9786 - val_loss: 0.0812 - val_accuracy: 0.9745\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0736 - accuracy: 0.9780 - val_loss: 0.0916 - val_accuracy: 0.9794\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0596 - accuracy: 0.9834 - val_loss: 0.0520 - val_accuracy: 0.9857\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 8s 8ms/step - loss: 0.0747 - accuracy: 0.9797 - val_loss: 0.0439 - val_accuracy: 0.9928\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 7s 7ms/step - loss: 0.0625 - accuracy: 0.9848 - val_loss: 0.1255 - val_accuracy: 0.9675\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history_final = model_final.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 2ms/step\n",
      "F1 Score: 0.7447995941146627\n"
     ]
    }
   ],
   "source": [
    "# f1 score\n",
    "y_pred = model_final.predict(X_val)\n",
    "y_pred = (y_pred > 0.5)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('F1 Score:', f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9674854557207498\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCAIML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
