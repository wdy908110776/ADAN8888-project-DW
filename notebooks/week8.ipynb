{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv('../data/processed/train_data_processed.csv')\n",
    "test = pd.read_csv('../data/processed/test_data_processed.csv')\n",
    "val = pd.read_csv('../data/processed/val_data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more feature engineering\n",
    "# use encoder to encode OCCURRED_ON_DATE column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['OCCURRED_ON_DATE'] = le.fit_transform(train['OCCURRED_ON_DATE'])\n",
    "test['OCCURRED_ON_DATE'] = le.transform(test['OCCURRED_ON_DATE'])\n",
    "val['OCCURRED_ON_DATE'] = le.transform(val['OCCURRED_ON_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/datetime_encoder.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save le \n",
    "import joblib\n",
    "joblib.dump(le, '../models/datetime_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop _id column\n",
    "\n",
    "test = test.drop('_id', axis=1)\n",
    "val = val.drop('_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable\n",
    "y_train = train['Severe_crimes']\n",
    "y_test = test['Severe_crimes']\n",
    "y_val = val['Severe_crimes']\n",
    "\n",
    "# define the features\n",
    "X_train = train.drop(['Severe_crimes'], axis=1)\n",
    "X_test = test.drop(['Severe_crimes'], axis=1)\n",
    "X_val = val.drop(['Severe_crimes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 1ms/step - loss: 7.9325 - accuracy: 0.8982 - val_loss: 0.1805 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.3513 - accuracy: 0.9305 - val_loss: 0.1896 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2512 - accuracy: 0.9317 - val_loss: 0.1779 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2312 - accuracy: 0.9321 - val_loss: 0.1800 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.9322 - val_loss: 0.1875 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2030 - accuracy: 0.9323 - val_loss: 0.1539 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1804 - accuracy: 0.9323 - val_loss: 0.1323 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9324 - val_loss: 0.1121 - val_accuracy: 0.9365\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9324 - val_loss: 0.1056 - val_accuracy: 0.9365\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.9323 - val_loss: 0.1168 - val_accuracy: 0.9365\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.1341 - accuracy: 0.9323 - val_loss: 0.1055 - val_accuracy: 0.9365\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1298 - accuracy: 0.9475 - val_loss: 0.0985 - val_accuracy: 0.9712\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1251 - accuracy: 0.9577 - val_loss: 0.0957 - val_accuracy: 0.9708\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1253 - accuracy: 0.9602 - val_loss: 0.0983 - val_accuracy: 0.9703\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1217 - accuracy: 0.9614 - val_loss: 0.1069 - val_accuracy: 0.9736\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9635 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1158 - accuracy: 0.9651 - val_loss: 0.0924 - val_accuracy: 0.9730\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9678 - val_loss: 0.0924 - val_accuracy: 0.9726\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.1095 - accuracy: 0.9679 - val_loss: 0.0939 - val_accuracy: 0.9721\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1081 - accuracy: 0.9677 - val_loss: 0.0906 - val_accuracy: 0.9717\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9690 - val_loss: 0.0862 - val_accuracy: 0.9745\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9689 - val_loss: 0.0892 - val_accuracy: 0.9739\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9691 - val_loss: 0.0936 - val_accuracy: 0.9740\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9700 - val_loss: 0.0879 - val_accuracy: 0.9733\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1032 - accuracy: 0.9701 - val_loss: 0.0873 - val_accuracy: 0.9736\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9698 - val_loss: 0.0886 - val_accuracy: 0.9745\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9699 - val_loss: 0.0877 - val_accuracy: 0.9703\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9702 - val_loss: 0.0869 - val_accuracy: 0.9744\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9699 - val_loss: 0.0862 - val_accuracy: 0.9749\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9691 - val_loss: 0.0925 - val_accuracy: 0.9747\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9708 - val_loss: 0.0833 - val_accuracy: 0.9745\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9705 - val_loss: 0.0861 - val_accuracy: 0.9767\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9701 - val_loss: 0.0817 - val_accuracy: 0.9757\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9704 - val_loss: 0.0809 - val_accuracy: 0.9765\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0933 - accuracy: 0.9704 - val_loss: 0.0782 - val_accuracy: 0.9766\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9711 - val_loss: 0.0776 - val_accuracy: 0.9754\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9723 - val_loss: 0.0742 - val_accuracy: 0.9771\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.9721 - val_loss: 0.0771 - val_accuracy: 0.9763\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0878 - accuracy: 0.9729 - val_loss: 0.0748 - val_accuracy: 0.9778\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0860 - accuracy: 0.9732 - val_loss: 0.0763 - val_accuracy: 0.9785\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9735 - val_loss: 0.0683 - val_accuracy: 0.9796\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0859 - accuracy: 0.9732 - val_loss: 0.0752 - val_accuracy: 0.9776\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9741 - val_loss: 0.0684 - val_accuracy: 0.9791\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0842 - accuracy: 0.9744 - val_loss: 0.0693 - val_accuracy: 0.9884\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0823 - accuracy: 0.9746 - val_loss: 0.0612 - val_accuracy: 0.9902\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9738 - val_loss: 0.0713 - val_accuracy: 0.9807\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0821 - accuracy: 0.9754 - val_loss: 0.0626 - val_accuracy: 0.9870\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0822 - accuracy: 0.9755 - val_loss: 0.0620 - val_accuracy: 0.9799\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0810 - accuracy: 0.9747 - val_loss: 0.0656 - val_accuracy: 0.9780\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 0.0649 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# build a CNN model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=7, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 0s 795us/step\n",
      "Accuracy: 0.9791855203619909\n",
      "Confusion Matrix: [[14274   213]\n",
      " [  109   874]]\n",
      "F1 Score: 0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "# use the model on validation data and evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# evaluate the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:', confusion)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 512)               4096      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178689 (698.00 KB)\n",
      "Trainable params: 178689 (698.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 4s 3ms/step - loss: 2.5333 - accuracy: 0.8914 - val_loss: 0.4200 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.2920 - accuracy: 0.9247 - val_loss: 0.2220 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.2225 - accuracy: 0.9291 - val_loss: 0.1823 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1881 - accuracy: 0.9305 - val_loss: 0.1579 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1665 - accuracy: 0.9311 - val_loss: 0.1559 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1468 - accuracy: 0.9317 - val_loss: 0.1628 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1377 - accuracy: 0.9330 - val_loss: 0.1140 - val_accuracy: 0.9654\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1352 - accuracy: 0.9567 - val_loss: 0.1542 - val_accuracy: 0.9707\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1249 - accuracy: 0.9630 - val_loss: 0.1107 - val_accuracy: 0.9743\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1269 - accuracy: 0.9672 - val_loss: 0.1377 - val_accuracy: 0.9712\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1217 - accuracy: 0.9677 - val_loss: 0.1203 - val_accuracy: 0.9714\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1207 - accuracy: 0.9677 - val_loss: 0.1256 - val_accuracy: 0.9736\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1194 - accuracy: 0.9690 - val_loss: 0.0894 - val_accuracy: 0.9734\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1180 - accuracy: 0.9701 - val_loss: 0.0901 - val_accuracy: 0.9749\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1131 - accuracy: 0.9703 - val_loss: 0.1086 - val_accuracy: 0.9681\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1120 - accuracy: 0.9693 - val_loss: 0.0852 - val_accuracy: 0.9736\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1116 - accuracy: 0.9708 - val_loss: 0.1043 - val_accuracy: 0.9741\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9716 - val_loss: 0.1344 - val_accuracy: 0.9628\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1133 - accuracy: 0.9719 - val_loss: 0.1083 - val_accuracy: 0.9719\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1115 - accuracy: 0.9715 - val_loss: 0.1388 - val_accuracy: 0.9660\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1072 - accuracy: 0.9713 - val_loss: 0.1331 - val_accuracy: 0.9730\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1091 - accuracy: 0.9708 - val_loss: 0.1107 - val_accuracy: 0.9755\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1060 - accuracy: 0.9720 - val_loss: 0.1056 - val_accuracy: 0.9721\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.9719 - val_loss: 0.1124 - val_accuracy: 0.9685\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1089 - accuracy: 0.9717 - val_loss: 0.1076 - val_accuracy: 0.9701\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1042 - accuracy: 0.9726 - val_loss: 0.0852 - val_accuracy: 0.9761\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1121 - accuracy: 0.9715 - val_loss: 0.2034 - val_accuracy: 0.9711\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1079 - accuracy: 0.9719 - val_loss: 0.1039 - val_accuracy: 0.9654\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.9712 - val_loss: 0.1325 - val_accuracy: 0.9693\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1120 - accuracy: 0.9722 - val_loss: 0.1633 - val_accuracy: 0.9671\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1028 - accuracy: 0.9730 - val_loss: 0.1031 - val_accuracy: 0.9708\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1023 - accuracy: 0.9729 - val_loss: 0.1175 - val_accuracy: 0.9681\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1100 - accuracy: 0.9710 - val_loss: 0.1756 - val_accuracy: 0.9635\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1050 - accuracy: 0.9720 - val_loss: 0.1362 - val_accuracy: 0.9711\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1094 - accuracy: 0.9723 - val_loss: 0.1098 - val_accuracy: 0.9705\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1054 - accuracy: 0.9723 - val_loss: 0.1045 - val_accuracy: 0.9669\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1050 - accuracy: 0.9725 - val_loss: 0.0954 - val_accuracy: 0.9665\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1019 - accuracy: 0.9723 - val_loss: 0.0868 - val_accuracy: 0.9681\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1081 - accuracy: 0.9714 - val_loss: 0.1047 - val_accuracy: 0.9716\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9713 - val_loss: 0.2799 - val_accuracy: 0.9487\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1069 - accuracy: 0.9719 - val_loss: 0.1276 - val_accuracy: 0.9658\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1021 - accuracy: 0.9730 - val_loss: 0.1558 - val_accuracy: 0.9649\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1039 - accuracy: 0.9727 - val_loss: 0.1147 - val_accuracy: 0.9754\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1006 - accuracy: 0.9728 - val_loss: 0.0899 - val_accuracy: 0.9696\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1022 - accuracy: 0.9727 - val_loss: 0.0786 - val_accuracy: 0.9762\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1011 - accuracy: 0.9714 - val_loss: 0.1061 - val_accuracy: 0.9661\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1010 - accuracy: 0.9701 - val_loss: 0.1178 - val_accuracy: 0.9625\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1025 - accuracy: 0.9715 - val_loss: 0.1355 - val_accuracy: 0.9619\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1047 - accuracy: 0.9722 - val_loss: 0.0819 - val_accuracy: 0.9760\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 3s 3ms/step - loss: 0.1015 - accuracy: 0.9717 - val_loss: 0.1352 - val_accuracy: 0.9642\n"
     ]
    }
   ],
   "source": [
    "# build a deeper CNN model\n",
    "model_deeper = Sequential()\n",
    "model_deeper.add(Dense(512, input_dim=7, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(256, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(128, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(64, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(32, activation='relu'))\n",
    "model_deeper.add(Dropout(0.5))\n",
    "model_deeper.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model_deeper.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_deeper.summary()\n",
    "\n",
    "# fit the model\n",
    "history_deeper = model_deeper.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 1ms/step\n",
      "Accuracy: 0.9641887524240466\n",
      "Confusion Matrix: [[14004   483]\n",
      " [   71   912]]\n",
      "F1 Score: 0.7670311185870479\n"
     ]
    }
   ],
   "source": [
    "# use the model on validation data and evaluate\n",
    "y_pred = model_deeper.predict(X_val)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# evaluate the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:', confusion)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 2ms/step - loss: 0.4434 - accuracy: 0.9244 - val_loss: 0.1218 - val_accuracy: 0.9410\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1362 - accuracy: 0.9379 - val_loss: 0.0995 - val_accuracy: 0.9589\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1198 - accuracy: 0.9512 - val_loss: 0.0948 - val_accuracy: 0.9665\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.9600 - val_loss: 0.0952 - val_accuracy: 0.9636\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9656 - val_loss: 0.0901 - val_accuracy: 0.9767\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9679 - val_loss: 0.0866 - val_accuracy: 0.9749\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9709 - val_loss: 0.0858 - val_accuracy: 0.9742\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9733 - val_loss: 0.0816 - val_accuracy: 0.9778\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.9734 - val_loss: 0.0790 - val_accuracy: 0.9776\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0857 - accuracy: 0.9746 - val_loss: 0.0808 - val_accuracy: 0.9769\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9747 - val_loss: 0.0801 - val_accuracy: 0.9769\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 0.0772 - val_accuracy: 0.9800\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0811 - accuracy: 0.9761 - val_loss: 0.0729 - val_accuracy: 0.9789\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0787 - accuracy: 0.9768 - val_loss: 0.0708 - val_accuracy: 0.9783\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.9757 - val_loss: 0.0689 - val_accuracy: 0.9804\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0784 - accuracy: 0.9765 - val_loss: 0.0669 - val_accuracy: 0.9820\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0782 - accuracy: 0.9756 - val_loss: 0.0713 - val_accuracy: 0.9822\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0755 - accuracy: 0.9777 - val_loss: 0.0667 - val_accuracy: 0.9803\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.0678 - val_accuracy: 0.9820\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 0.0609 - val_accuracy: 0.9833\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0684 - accuracy: 0.9806 - val_loss: 0.0607 - val_accuracy: 0.9783\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.0628 - val_accuracy: 0.9802\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0669 - accuracy: 0.9808 - val_loss: 0.0538 - val_accuracy: 0.9873\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0645 - accuracy: 0.9816 - val_loss: 0.0514 - val_accuracy: 0.9867\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0636 - accuracy: 0.9823 - val_loss: 0.0533 - val_accuracy: 0.9880\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0613 - accuracy: 0.9831 - val_loss: 0.0531 - val_accuracy: 0.9839\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0615 - accuracy: 0.9832 - val_loss: 0.0522 - val_accuracy: 0.9853\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0600 - accuracy: 0.9841 - val_loss: 0.0496 - val_accuracy: 0.9884\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0611 - accuracy: 0.9838 - val_loss: 0.0532 - val_accuracy: 0.9836\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0587 - accuracy: 0.9841 - val_loss: 0.0534 - val_accuracy: 0.9909\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0561 - accuracy: 0.9858 - val_loss: 0.0430 - val_accuracy: 0.9904\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0604 - accuracy: 0.9847 - val_loss: 0.0454 - val_accuracy: 0.9919\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0584 - accuracy: 0.9847 - val_loss: 0.0468 - val_accuracy: 0.9902\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0566 - accuracy: 0.9858 - val_loss: 0.0481 - val_accuracy: 0.9900\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0554 - accuracy: 0.9864 - val_loss: 0.0489 - val_accuracy: 0.9867\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0552 - accuracy: 0.9872 - val_loss: 0.0423 - val_accuracy: 0.9930\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0537 - accuracy: 0.9882 - val_loss: 0.0408 - val_accuracy: 0.9932\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0597 - accuracy: 0.9848 - val_loss: 0.0453 - val_accuracy: 0.9927\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0607 - accuracy: 0.9844 - val_loss: 0.0515 - val_accuracy: 0.9818\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0580 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9930\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0586 - accuracy: 0.9847 - val_loss: 0.0464 - val_accuracy: 0.9907\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0576 - accuracy: 0.9852 - val_loss: 0.0468 - val_accuracy: 0.9917\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0552 - accuracy: 0.9861 - val_loss: 0.0469 - val_accuracy: 0.9910\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0582 - accuracy: 0.9856 - val_loss: 0.0464 - val_accuracy: 0.9921\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0571 - accuracy: 0.9862 - val_loss: 0.0412 - val_accuracy: 0.9920\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0555 - accuracy: 0.9856 - val_loss: 0.0425 - val_accuracy: 0.9931\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0549 - accuracy: 0.9860 - val_loss: 0.0408 - val_accuracy: 0.9930\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0543 - accuracy: 0.9866 - val_loss: 0.0402 - val_accuracy: 0.9931\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0579 - accuracy: 0.9854 - val_loss: 0.0424 - val_accuracy: 0.9931\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0497 - accuracy: 0.9885 - val_loss: 0.0422 - val_accuracy: 0.9930\n",
      "484/484 [==============================] - 0s 741us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 1ms/step - loss: 1.6378 - accuracy: 0.9097 - val_loss: 0.1528 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1863 - accuracy: 0.9322 - val_loss: 0.1213 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1467 - accuracy: 0.9330 - val_loss: 0.1024 - val_accuracy: 0.9399\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1277 - accuracy: 0.9459 - val_loss: 0.0951 - val_accuracy: 0.9685\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1165 - accuracy: 0.9560 - val_loss: 0.0974 - val_accuracy: 0.9682\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9628 - val_loss: 0.0890 - val_accuracy: 0.9731\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1046 - accuracy: 0.9657 - val_loss: 0.0866 - val_accuracy: 0.9685\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9671 - val_loss: 0.0874 - val_accuracy: 0.9716\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9683 - val_loss: 0.0872 - val_accuracy: 0.9702\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0974 - accuracy: 0.9700 - val_loss: 0.0830 - val_accuracy: 0.9738\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9693 - val_loss: 0.0825 - val_accuracy: 0.9749\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9695 - val_loss: 0.0829 - val_accuracy: 0.9742\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0912 - accuracy: 0.9718 - val_loss: 0.0820 - val_accuracy: 0.9729\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9720 - val_loss: 0.0789 - val_accuracy: 0.9749\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9722 - val_loss: 0.0862 - val_accuracy: 0.9699\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0867 - accuracy: 0.9732 - val_loss: 0.0781 - val_accuracy: 0.9776\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0866 - accuracy: 0.9726 - val_loss: 0.0761 - val_accuracy: 0.9763\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0863 - accuracy: 0.9740 - val_loss: 0.0834 - val_accuracy: 0.9712\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.0722 - val_accuracy: 0.9776\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.0749 - val_accuracy: 0.9771\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0803 - accuracy: 0.9755 - val_loss: 0.0759 - val_accuracy: 0.9798\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0798 - accuracy: 0.9752 - val_loss: 0.0717 - val_accuracy: 0.9767\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.0651 - val_accuracy: 0.9787\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0769 - accuracy: 0.9770 - val_loss: 0.0872 - val_accuracy: 0.9602\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0648 - val_accuracy: 0.9838\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0760 - accuracy: 0.9770 - val_loss: 0.0631 - val_accuracy: 0.9798\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0746 - accuracy: 0.9783 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.0608 - val_accuracy: 0.9833\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.0573 - val_accuracy: 0.9867\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0703 - accuracy: 0.9795 - val_loss: 0.0588 - val_accuracy: 0.9842\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.0539 - val_accuracy: 0.9840\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0691 - accuracy: 0.9793 - val_loss: 0.0579 - val_accuracy: 0.9835\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0695 - accuracy: 0.9794 - val_loss: 0.0627 - val_accuracy: 0.9789\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 0.0549 - val_accuracy: 0.9868\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0705 - accuracy: 0.9789 - val_loss: 0.0599 - val_accuracy: 0.9838\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0752 - accuracy: 0.9774 - val_loss: 0.0535 - val_accuracy: 0.9838\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.0542 - val_accuracy: 0.9882\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0655 - accuracy: 0.9815 - val_loss: 0.0516 - val_accuracy: 0.9882\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0660 - accuracy: 0.9816 - val_loss: 0.0590 - val_accuracy: 0.9818\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0651 - accuracy: 0.9814 - val_loss: 0.0719 - val_accuracy: 0.9746\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0622 - accuracy: 0.9829 - val_loss: 0.0428 - val_accuracy: 0.9911\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0591 - accuracy: 0.9844 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0627 - accuracy: 0.9822 - val_loss: 0.0496 - val_accuracy: 0.9878\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0626 - accuracy: 0.9831 - val_loss: 0.0526 - val_accuracy: 0.9822\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0634 - accuracy: 0.9835 - val_loss: 0.0587 - val_accuracy: 0.9893\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0660 - accuracy: 0.9826 - val_loss: 0.0488 - val_accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0624 - accuracy: 0.9847 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0609 - accuracy: 0.9847 - val_loss: 0.0503 - val_accuracy: 0.9926\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0621 - accuracy: 0.9837 - val_loss: 0.0444 - val_accuracy: 0.9928\n",
      "484/484 [==============================] - 0s 743us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 1ms/step - loss: 4.3022 - accuracy: 0.9059 - val_loss: 0.1839 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2702 - accuracy: 0.9307 - val_loss: 0.1757 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2149 - accuracy: 0.9319 - val_loss: 0.1706 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1926 - accuracy: 0.9323 - val_loss: 0.1374 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1714 - accuracy: 0.9322 - val_loss: 0.1245 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1534 - accuracy: 0.9324 - val_loss: 0.1083 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1425 - accuracy: 0.9324 - val_loss: 0.1178 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1312 - accuracy: 0.9340 - val_loss: 0.0970 - val_accuracy: 0.9596\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1234 - accuracy: 0.9526 - val_loss: 0.1009 - val_accuracy: 0.9710\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9581 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1170 - accuracy: 0.9604 - val_loss: 0.0974 - val_accuracy: 0.9709\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.9621 - val_loss: 0.0940 - val_accuracy: 0.9715\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.9618 - val_loss: 0.0923 - val_accuracy: 0.9713\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1109 - accuracy: 0.9622 - val_loss: 0.0882 - val_accuracy: 0.9708\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1078 - accuracy: 0.9620 - val_loss: 0.0886 - val_accuracy: 0.9714\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9664 - val_loss: 0.0868 - val_accuracy: 0.9726\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9680 - val_loss: 0.0863 - val_accuracy: 0.9701\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9701 - val_loss: 0.0839 - val_accuracy: 0.9732\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9715 - val_loss: 0.0860 - val_accuracy: 0.9732\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0937 - accuracy: 0.9722 - val_loss: 0.0807 - val_accuracy: 0.9772\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9725 - val_loss: 0.0830 - val_accuracy: 0.9737\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.9734 - val_loss: 0.0772 - val_accuracy: 0.9755\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0896 - accuracy: 0.9728 - val_loss: 0.0818 - val_accuracy: 0.9756\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0865 - accuracy: 0.9741 - val_loss: 0.0767 - val_accuracy: 0.9768\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0880 - accuracy: 0.9745 - val_loss: 0.0887 - val_accuracy: 0.9772\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0858 - accuracy: 0.9747 - val_loss: 0.0725 - val_accuracy: 0.9769\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0858 - accuracy: 0.9747 - val_loss: 0.0740 - val_accuracy: 0.9761\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9758 - val_loss: 0.0710 - val_accuracy: 0.9768\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0829 - accuracy: 0.9763 - val_loss: 0.0717 - val_accuracy: 0.9779\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0837 - accuracy: 0.9756 - val_loss: 0.0687 - val_accuracy: 0.9782\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0808 - accuracy: 0.9766 - val_loss: 0.0774 - val_accuracy: 0.9793\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9764 - val_loss: 0.0672 - val_accuracy: 0.9779\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0795 - accuracy: 0.9770 - val_loss: 0.0781 - val_accuracy: 0.9775\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0780 - accuracy: 0.9770 - val_loss: 0.0662 - val_accuracy: 0.9784\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0761 - accuracy: 0.9776 - val_loss: 0.0637 - val_accuracy: 0.9811\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9774 - val_loss: 0.0656 - val_accuracy: 0.9809\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0734 - accuracy: 0.9789 - val_loss: 0.0652 - val_accuracy: 0.9776\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.0817 - val_accuracy: 0.9787\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0742 - accuracy: 0.9783 - val_loss: 0.0652 - val_accuracy: 0.9794\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0754 - accuracy: 0.9774 - val_loss: 0.0659 - val_accuracy: 0.9799\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0704 - accuracy: 0.9794 - val_loss: 0.0563 - val_accuracy: 0.9838\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0703 - accuracy: 0.9796 - val_loss: 0.0625 - val_accuracy: 0.9858\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0715 - accuracy: 0.9796 - val_loss: 0.0544 - val_accuracy: 0.9844\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0698 - accuracy: 0.9798 - val_loss: 0.0620 - val_accuracy: 0.9818\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0711 - accuracy: 0.9792 - val_loss: 0.0555 - val_accuracy: 0.9821\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.0695 - val_accuracy: 0.9840\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0725 - accuracy: 0.9788 - val_loss: 0.0611 - val_accuracy: 0.9798\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0704 - accuracy: 0.9799 - val_loss: 0.0530 - val_accuracy: 0.9880\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.0493 - val_accuracy: 0.9912\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0700 - accuracy: 0.9795 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "484/484 [==============================] - 0s 740us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 1ms/step - loss: 7.4854 - accuracy: 0.8873 - val_loss: 0.2093 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.3387 - accuracy: 0.9300 - val_loss: 0.1785 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2399 - accuracy: 0.9317 - val_loss: 0.1657 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.9320 - val_loss: 0.1404 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1730 - accuracy: 0.9324 - val_loss: 0.1187 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1590 - accuracy: 0.9324 - val_loss: 0.1112 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1466 - accuracy: 0.9326 - val_loss: 0.1013 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1321 - accuracy: 0.9526 - val_loss: 0.1044 - val_accuracy: 0.9692\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1219 - accuracy: 0.9603 - val_loss: 0.1023 - val_accuracy: 0.9676\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1161 - accuracy: 0.9637 - val_loss: 0.0981 - val_accuracy: 0.9717\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9656 - val_loss: 0.0960 - val_accuracy: 0.9696\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1097 - accuracy: 0.9661 - val_loss: 0.0956 - val_accuracy: 0.9706\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.9674 - val_loss: 0.0915 - val_accuracy: 0.9724\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1050 - accuracy: 0.9670 - val_loss: 0.0937 - val_accuracy: 0.9720\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1062 - accuracy: 0.9681 - val_loss: 0.0848 - val_accuracy: 0.9720\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1039 - accuracy: 0.9686 - val_loss: 0.0891 - val_accuracy: 0.9714\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9680 - val_loss: 0.0905 - val_accuracy: 0.9719\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9697 - val_loss: 0.0883 - val_accuracy: 0.9737\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9698 - val_loss: 0.0933 - val_accuracy: 0.9754\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9700 - val_loss: 0.0839 - val_accuracy: 0.9754\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0958 - accuracy: 0.9709 - val_loss: 0.0828 - val_accuracy: 0.9760\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0941 - accuracy: 0.9718 - val_loss: 0.0838 - val_accuracy: 0.9752\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9723 - val_loss: 0.0776 - val_accuracy: 0.9757\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9728 - val_loss: 0.0832 - val_accuracy: 0.9721\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9731 - val_loss: 0.0751 - val_accuracy: 0.9771\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9731 - val_loss: 0.0815 - val_accuracy: 0.9751\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9736 - val_loss: 0.0727 - val_accuracy: 0.9778\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9740 - val_loss: 0.0746 - val_accuracy: 0.9793\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9741 - val_loss: 0.0727 - val_accuracy: 0.9782\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.9733 - val_loss: 0.0736 - val_accuracy: 0.9779\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0859 - accuracy: 0.9740 - val_loss: 0.0744 - val_accuracy: 0.9780\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0840 - accuracy: 0.9750 - val_loss: 0.0711 - val_accuracy: 0.9771\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0844 - accuracy: 0.9752 - val_loss: 0.0705 - val_accuracy: 0.9764\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0862 - accuracy: 0.9738 - val_loss: 0.0693 - val_accuracy: 0.9761\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0856 - accuracy: 0.9741 - val_loss: 0.0646 - val_accuracy: 0.9791\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0831 - accuracy: 0.9755 - val_loss: 0.0654 - val_accuracy: 0.9799\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0817 - accuracy: 0.9755 - val_loss: 0.0733 - val_accuracy: 0.9764\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 0.0687 - val_accuracy: 0.9811\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0802 - accuracy: 0.9761 - val_loss: 0.0744 - val_accuracy: 0.9674\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0799 - accuracy: 0.9763 - val_loss: 0.0681 - val_accuracy: 0.9796\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0770 - accuracy: 0.9773 - val_loss: 0.0626 - val_accuracy: 0.9854\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0782 - accuracy: 0.9759 - val_loss: 0.0631 - val_accuracy: 0.9794\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0779 - accuracy: 0.9777 - val_loss: 0.0654 - val_accuracy: 0.9802\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0756 - accuracy: 0.9783 - val_loss: 0.0585 - val_accuracy: 0.9925\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0776 - accuracy: 0.9764 - val_loss: 0.0728 - val_accuracy: 0.9774\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0804 - accuracy: 0.9746 - val_loss: 0.0632 - val_accuracy: 0.9894\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9751 - val_loss: 0.0593 - val_accuracy: 0.9880\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0790 - accuracy: 0.9753 - val_loss: 0.0818 - val_accuracy: 0.9768\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0770 - accuracy: 0.9764 - val_loss: 0.0592 - val_accuracy: 0.9827\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0760 - accuracy: 0.9769 - val_loss: 0.0535 - val_accuracy: 0.9915\n",
      "484/484 [==============================] - 0s 737us/step\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 2s 1ms/step - loss: 6.8418 - accuracy: 0.9033 - val_loss: 0.1796 - val_accuracy: 0.9365\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.3208 - accuracy: 0.9314 - val_loss: 0.1805 - val_accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2491 - accuracy: 0.9319 - val_loss: 0.1673 - val_accuracy: 0.9365\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2186 - accuracy: 0.9321 - val_loss: 0.1553 - val_accuracy: 0.9365\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.2058 - accuracy: 0.9323 - val_loss: 0.1447 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1919 - accuracy: 0.9323 - val_loss: 0.1378 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1736 - accuracy: 0.9323 - val_loss: 0.1276 - val_accuracy: 0.9365\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1619 - accuracy: 0.9324 - val_loss: 0.1132 - val_accuracy: 0.9365\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1489 - accuracy: 0.9323 - val_loss: 0.1110 - val_accuracy: 0.9365\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1478 - accuracy: 0.9324 - val_loss: 0.1071 - val_accuracy: 0.9365\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1442 - accuracy: 0.9323 - val_loss: 0.1021 - val_accuracy: 0.9365\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1420 - accuracy: 0.9324 - val_loss: 0.1061 - val_accuracy: 0.9365\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1367 - accuracy: 0.9323 - val_loss: 0.1034 - val_accuracy: 0.9365\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1328 - accuracy: 0.9339 - val_loss: 0.1040 - val_accuracy: 0.9709\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1296 - accuracy: 0.9531 - val_loss: 0.1029 - val_accuracy: 0.9718\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1231 - accuracy: 0.9605 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.9610 - val_loss: 0.0959 - val_accuracy: 0.9725\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1180 - accuracy: 0.9632 - val_loss: 0.0979 - val_accuracy: 0.9730\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.9646 - val_loss: 0.1071 - val_accuracy: 0.9684\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1168 - accuracy: 0.9649 - val_loss: 0.0938 - val_accuracy: 0.9718\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9657 - val_loss: 0.0907 - val_accuracy: 0.9715\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9668 - val_loss: 0.0947 - val_accuracy: 0.9741\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1075 - accuracy: 0.9682 - val_loss: 0.0930 - val_accuracy: 0.9745\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9678 - val_loss: 0.0910 - val_accuracy: 0.9761\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1072 - accuracy: 0.9680 - val_loss: 0.0927 - val_accuracy: 0.9735\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1047 - accuracy: 0.9676 - val_loss: 0.0893 - val_accuracy: 0.9738\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9680 - val_loss: 0.0888 - val_accuracy: 0.9734\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9682 - val_loss: 0.0861 - val_accuracy: 0.9726\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9699 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0937 - accuracy: 0.9724 - val_loss: 0.0773 - val_accuracy: 0.9794\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0932 - accuracy: 0.9719 - val_loss: 0.0743 - val_accuracy: 0.9789\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9746 - val_loss: 0.0726 - val_accuracy: 0.9791\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9723 - val_loss: 0.0727 - val_accuracy: 0.9780\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0873 - accuracy: 0.9737 - val_loss: 0.0690 - val_accuracy: 0.9880\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0858 - accuracy: 0.9741 - val_loss: 0.0689 - val_accuracy: 0.9778\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0860 - accuracy: 0.9741 - val_loss: 0.0673 - val_accuracy: 0.9793\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9742 - val_loss: 0.0748 - val_accuracy: 0.9752\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0833 - accuracy: 0.9745 - val_loss: 0.0645 - val_accuracy: 0.9830\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9740 - val_loss: 0.0621 - val_accuracy: 0.9809\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9758 - val_loss: 0.0704 - val_accuracy: 0.9778\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0821 - accuracy: 0.9746 - val_loss: 0.0628 - val_accuracy: 0.9873\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0826 - accuracy: 0.9734 - val_loss: 0.0673 - val_accuracy: 0.9786\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9733 - val_loss: 0.0677 - val_accuracy: 0.9788\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0823 - accuracy: 0.9742 - val_loss: 0.0645 - val_accuracy: 0.9810\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0827 - accuracy: 0.9736 - val_loss: 0.0633 - val_accuracy: 0.9797\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.0620 - val_accuracy: 0.9795\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.0630 - val_accuracy: 0.9787\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0817 - accuracy: 0.9738 - val_loss: 0.0631 - val_accuracy: 0.9819\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0799 - accuracy: 0.9749 - val_loss: 0.0585 - val_accuracy: 0.9828\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9728 - val_loss: 0.0676 - val_accuracy: 0.9790\n",
      "484/484 [==============================] - 0s 780us/step\n",
      "[0.9413663259817104, 0.9408630793819927, 0.8968335035750765, 0.9301333333333335, 0.8423095584667638]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test different dropout rates\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "f1_scores = []\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=7, activation='relu'))\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "    # use the model on validation data and evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    # f1 score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f1_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the dropout rates vs f1 scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dropout_rates, f1_scores)\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Dropout Rate vs F1 Score')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 1024)              8192      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 707585 (2.70 MB)\n",
      "Trainable params: 707585 (2.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "964/964 [==============================] - 7s 6ms/step - loss: 0.3402 - accuracy: 0.9321 - val_loss: 0.1007 - val_accuracy: 0.9475\n",
      "Epoch 2/50\n",
      "964/964 [==============================] - 6s 7ms/step - loss: 0.1100 - accuracy: 0.9616 - val_loss: 0.0873 - val_accuracy: 0.9680\n",
      "Epoch 3/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0967 - accuracy: 0.9687 - val_loss: 0.0861 - val_accuracy: 0.9742\n",
      "Epoch 4/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0955 - accuracy: 0.9705 - val_loss: 0.0891 - val_accuracy: 0.9683\n",
      "Epoch 5/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0907 - accuracy: 0.9722 - val_loss: 0.0809 - val_accuracy: 0.9732\n",
      "Epoch 6/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0883 - accuracy: 0.9734 - val_loss: 0.0752 - val_accuracy: 0.9751\n",
      "Epoch 7/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0846 - accuracy: 0.9741 - val_loss: 0.0752 - val_accuracy: 0.9750\n",
      "Epoch 8/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0847 - accuracy: 0.9752 - val_loss: 0.0712 - val_accuracy: 0.9773\n",
      "Epoch 9/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0816 - accuracy: 0.9763 - val_loss: 0.0844 - val_accuracy: 0.9769\n",
      "Epoch 10/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0763 - accuracy: 0.9775 - val_loss: 0.0675 - val_accuracy: 0.9790\n",
      "Epoch 11/50\n",
      "964/964 [==============================] - 5s 6ms/step - loss: 0.0779 - accuracy: 0.9784 - val_loss: 0.0665 - val_accuracy: 0.9797\n",
      "Epoch 12/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0740 - accuracy: 0.9794 - val_loss: 0.0603 - val_accuracy: 0.9805\n",
      "Epoch 13/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0695 - accuracy: 0.9799 - val_loss: 0.0699 - val_accuracy: 0.9796\n",
      "Epoch 14/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0678 - accuracy: 0.9813 - val_loss: 0.0596 - val_accuracy: 0.9800\n",
      "Epoch 15/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0711 - accuracy: 0.9801 - val_loss: 0.0630 - val_accuracy: 0.9794\n",
      "Epoch 16/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0695 - accuracy: 0.9807 - val_loss: 0.0720 - val_accuracy: 0.9800\n",
      "Epoch 17/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0698 - accuracy: 0.9819 - val_loss: 0.0546 - val_accuracy: 0.9828\n",
      "Epoch 18/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0724 - accuracy: 0.9789 - val_loss: 0.0869 - val_accuracy: 0.9740\n",
      "Epoch 19/50\n",
      "964/964 [==============================] - 5s 6ms/step - loss: 0.0727 - accuracy: 0.9800 - val_loss: 0.0748 - val_accuracy: 0.9758\n",
      "Epoch 20/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0753 - accuracy: 0.9790 - val_loss: 0.0702 - val_accuracy: 0.9791\n",
      "Epoch 21/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0682 - accuracy: 0.9813 - val_loss: 0.0811 - val_accuracy: 0.9783\n",
      "Epoch 22/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0748 - accuracy: 0.9778 - val_loss: 0.0635 - val_accuracy: 0.9831\n",
      "Epoch 23/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0719 - accuracy: 0.9798 - val_loss: 0.0828 - val_accuracy: 0.9757\n",
      "Epoch 24/50\n",
      "964/964 [==============================] - 5s 6ms/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 25/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0719 - accuracy: 0.9806 - val_loss: 0.0545 - val_accuracy: 0.9886\n",
      "Epoch 26/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0659 - accuracy: 0.9824 - val_loss: 0.0752 - val_accuracy: 0.9769\n",
      "Epoch 27/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0734 - accuracy: 0.9808 - val_loss: 0.0619 - val_accuracy: 0.9805\n",
      "Epoch 28/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0703 - accuracy: 0.9816 - val_loss: 0.0684 - val_accuracy: 0.9790\n",
      "Epoch 29/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0701 - accuracy: 0.9803 - val_loss: 0.1037 - val_accuracy: 0.9778\n",
      "Epoch 30/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.0444 - val_accuracy: 0.9926\n",
      "Epoch 31/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0683 - accuracy: 0.9815 - val_loss: 0.0710 - val_accuracy: 0.9773\n",
      "Epoch 32/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0710 - accuracy: 0.9811 - val_loss: 0.0772 - val_accuracy: 0.9752\n",
      "Epoch 33/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0663 - accuracy: 0.9817 - val_loss: 0.0432 - val_accuracy: 0.9915\n",
      "Epoch 34/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0735 - accuracy: 0.9788 - val_loss: 0.0646 - val_accuracy: 0.9787\n",
      "Epoch 35/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0698 - accuracy: 0.9802 - val_loss: 0.0710 - val_accuracy: 0.9784\n",
      "Epoch 36/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0664 - accuracy: 0.9820 - val_loss: 0.0710 - val_accuracy: 0.9790\n",
      "Epoch 37/50\n",
      "964/964 [==============================] - 5s 6ms/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.0503 - val_accuracy: 0.9831\n",
      "Epoch 38/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0528 - accuracy: 0.9883 - val_loss: 0.0828 - val_accuracy: 0.9781\n",
      "Epoch 39/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.0735 - val_accuracy: 0.9755\n",
      "Epoch 40/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0756 - accuracy: 0.9775 - val_loss: 0.0497 - val_accuracy: 0.9911\n",
      "Epoch 41/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0710 - accuracy: 0.9796 - val_loss: 0.0487 - val_accuracy: 0.9884\n",
      "Epoch 42/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0687 - accuracy: 0.9805 - val_loss: 0.0673 - val_accuracy: 0.9786\n",
      "Epoch 43/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0720 - accuracy: 0.9785 - val_loss: 0.0722 - val_accuracy: 0.9761\n",
      "Epoch 44/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 0.0752 - val_accuracy: 0.9758\n",
      "Epoch 45/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.0751 - val_accuracy: 0.9757\n",
      "Epoch 46/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0820 - accuracy: 0.9742 - val_loss: 0.0783 - val_accuracy: 0.9742\n",
      "Epoch 47/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0830 - accuracy: 0.9736 - val_loss: 0.0744 - val_accuracy: 0.9758\n",
      "Epoch 48/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0817 - accuracy: 0.9744 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 49/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0754 - accuracy: 0.9776 - val_loss: 0.0643 - val_accuracy: 0.9788\n",
      "Epoch 50/50\n",
      "964/964 [==============================] - 6s 6ms/step - loss: 0.0645 - accuracy: 0.9822 - val_loss: 0.0416 - val_accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "# final model, use a 0.15 dropout rate\n",
    "model_final = Sequential()\n",
    "model_final.add(Dense(1024, input_dim=7, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(512, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(128, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(64, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(32, activation='relu'))\n",
    "model_final.add(Dropout(0.15))\n",
    "model_final.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_final.summary()\n",
    "\n",
    "# fit the model\n",
    "history_final = model_final.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 2ms/step\n",
      "F1 Score: 0.9313371192565824\n"
     ]
    }
   ],
   "source": [
    "# f1 score\n",
    "y_pred = model_final.predict(X_val)\n",
    "y_pred = (y_pred > 0.5)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('F1 Score:', f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCAIML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
